<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Customize your learning as a data scientist | Yassir Birouk</title> <meta name="author" content="Yassir Birouk"> <meta name="description" content="This single skill will open a whole world of new possibilities for you"> <meta name="keywords" content="Ml Engineer, AI, data-scientist, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://dbzxexpert.github.io/blog/2020/Customize-your-learning-as-a-data-scientist/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?3dd82e91913a2c1265c0f80e41ff39e2"></script> <script src="/assets/js/dark_mode.js?6458e63976eae16c0cbe86b97023895a"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Yassir </span>Birouk</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Customize your learning as a data scientist</h1> <p class="post-meta">October 2, 2020</p> <p class="post-tags"> <a href="/blog/2020"> <i class="fa-solid fa-calendar fa-sm"></i> 2020 </a>   ·   <a href="/blog/tag/scraping"> <i class="fa-solid fa-hashtag fa-sm"></i> scraping,</a>   <a href="/blog/tag/data"> <i class="fa-solid fa-hashtag fa-sm"></i> data</a>     ·   <a href="/blog/category/day-to-day"> <i class="fa-solid fa-tag fa-sm"></i> day-to-day</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <p><a href="https://postimg.cc/RNswBrPs" rel="external nofollow noopener" target="_blank"><img src="https://i.postimg.cc/2SmGnrnD/image.png" alt="image.png"></a></p> <p>Have you ever got the idea for an awesome data science project, looked up the data you’ll need online, but it’s nowhere to be found? Unfortunately, not every dataset you’ll ever require is available online. So, what are your options? Should you abandon your concept and return to Kaggle? No! A true data scientist should be able to gather his or her own DATA!</p> <h1 id="whats-web-scraping-and-why-learn-it">What’s Web Scraping and why learn it?</h1> <p>The internet is the single most important source of data; it is a virtual record of human knowledge, at least for the last 20 years. Web scraping is the skill of obtaining data from the internet as a Data Scientist. It’s a fantastic tool that offers up so many possibilities for unique projects.</p> <p><strong>Please be in mind that certain websites forbid scraping and may block your IP address if you scrape too frequently or maliciously..</strong></p> <h1 id="how-do-we-scrape"><strong>How do we scrape?</strong></h1> <p>There are two approaches when it comes to web scraping.</p> <p><strong>Request-based scraping</strong>: With this method, we will submit a request to the website’s server, which will return the HTML of the page, which is the same content that you see when you click “View page source” in Google Chrome, which you can try right now by clicking <strong>ctrl+u</strong>.Then, normally, we will use a library to parse the HTML and retrieve the desired data. This approach is simple, lightweight, and very fast; however, it is not perfect, and there is one disadvantage that may deter you from using it; in fact, most modern websites nowadays use JavaScript to render their content, IE: you don’t see the content of the page until the JavaScript executes, which the request method cannot handle.</p> <p><strong>Request-based scraping</strong>: In this strategy, we will submit a request to the website’s server, which will return the HTML of the page, which is the same content that you see when you click “View page source” in Google Chrome, which you can try right now by clicking <strong>ctrl+u</strong>.Then we normally use a library to parse the HTML and extract the desired data. This approach is simple, lightweight, and very fast; however, it is not perfect, and there is one drawback that may deter you from using it; in fact, most modern websites nowadays use JavaScript to render their content, IE: you don’t see the content of the page until after the JavaScript executes, which the request method cannot handle.</p> <h1 id="scrape-using-selenium">Scrape using selenium:</h1> <p>Selenium is a popular web automation framework, but it can also be used for scraping! You can basically imitate any operation that a human can do manually using selenium. You may construct a bot that will take particular actions when something happens, or you can make selenium scan web sites and scrape data for you, which is what we’ll be doing in this tutorial.</p> <p>To parse the HTML we will be using beautiful soup.</p> <p>Here are documentation links for further reading. <a href="https://selenium-python.readthedocs.io/" rel="external nofollow noopener" target="_blank">selenium</a> and <a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/" rel="external nofollow noopener" target="_blank">beautiful soup</a></p> <h1 id="demo-scraping-jobs-from-indeeds-job-board">Demo: Scraping Jobs from Indeed’s Job board</h1> <p>Let’s get started; the purpose of this example is to scrape jobs from Indeed based on a search query and store them in a csv file.</p> <p>More precisely we are interested in:</p> <ul> <li>Job title</li> <li>Location of the job</li> <li>Company that posted the offer</li> <li>Job description</li> <li>When the job was posted</li> </ul> <p>First let’s import the libraries that we’il work with:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from bs4 import BeautifulSoup  
from webdriver_manager.chrome import ChromeDriverManager  
import pandas as pd  
from selenium import webdriver  
from selenium.webdriver.chrome.options import Options
chrome_options = Options()  
chrome_options.add_argument("--headless")
</code></pre></div></div> <ul> <li>Beautiful Soup is used to interface with HTML</li> <li>Pandas is used to output to csv</li> <li>The web driver is the real browser; we will use Chrome and configure it to run in <strong>headless mode</strong>, which means it will run in the background and we will not be able to see a browser scrolling through the job sites; if you want to view the browser, you may delete it!</li> </ul> <p>The first step is to obtain the real job pages; fortunately, Lucky offers a search option; simply browse to:</p> <p>“https://fr.indeed.com/jobs?q=data+scientist&amp;start=10”</p> <p><a href="https://postimg.cc/62pY0VTT" rel="external nofollow noopener" target="_blank"><img src="https://i.postimg.cc/B6xkJM05/image.png" alt="image.png"></a></p> <p>You’ll be sent to the second page of data science jobs, where you may modify the search query by changing the <strong>q</strong> argument and the page number by changing the <strong>start</strong> argument. I’m using the Indeed Moroccan portal, but this will work in any nation.</p> <p>Two functions will be implemented. One is a helper method for navigating to a URL, extracting the HTML and converting it to a Beautiful Soup object with which we can interact, while the other extracts links to job pages:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def toSoup(url):  
    driver.get(url)  
    html = driver.page_source  
    soup = BeautifulSoup(html, 'lxml')  
    return soupdef getPageUrls(query,number):  
    url="[https://fr.indeed.com/emplois?q=](https:/fr.indeed.com/emplois?q=)"+str(query)+"&amp;start="+str(((number-1)\*10))  
    soup=toSoup(url)  
    maxPages=soup.find("div",{"id":"searchCountPages"}).text.strip().split(" ")[3]  
    return maxPages,[appendIndeedUrl(a["href"]) for a in soup.findAll("a",{"class":"jobtitle turnstileLink"})]
</code></pre></div></div> <p>Now that we have the URLs, let’s put them to use to extract what we want from the job page:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def paragraphArrayToSingleString(paragraphs):  
    string=""  
    for paragraph in paragraphs:  
        string=string+"\\n"+paragraph.text.strip()  
    return stringdef appendIndeedUrl(url):  
    return "[https://fr.indeed.com](https://fr.indeed.com)"+str(url)def processPage(url):  
    soup=toSoup(url)  
    title=soup.find("h1",{"class":"icl-u-xs-mb--xs icl-u-xs-mt--none jobsearch-JobInfoHeader-title"}).text.strip()  
    CompanyAndLocation=soup.find("div",{"class":"jobsearch-InlineCompanyRating icl-u-xs-mt--xs jobsearch-DesktopStickyContainer-companyrating"})  
    length=len(CompanyAndLocation)  
    if length==3:  
        company=CompanyAndLocation.findAll("div")[0].text.strip()  
        location=CompanyAndLocation.findAll("div")[2].text.strip()  
    else:  
        company="NAN"  
        location=CompanyAndLocation.findAll("div")[0].text.strip()  
    date=soup.find("div",{"class":"jobsearch-JobMetadataFooter"}).text.split("-")[1].strip()  
    description=paragraphArrayToSingleString(soup.find("div",{"id":"jobDescriptionText"}).findAll())  
    return {"title":title,"company":company,"location":location,"date":date,"description":description}def getMaxPages(query):  
    url="[https://fr.indeed.com/emplois?q=](https://fr.indeed.com/emplois?q=)"+str(query)
</code></pre></div></div> <p>We’re utilizing HTML characteristics like “class” and “id” to get the information we’re looking for; you can figure out how to choose the data you need by studying the website.</p> <p>Here’s an illustration of the title property:</p> <p><a href="https://postimg.cc/nXkDFyc9" rel="external nofollow noopener" target="_blank"><img src="https://i.postimg.cc/BvWcg3rp/image.png" alt="image.png"></a></p> <p>The title is a “h1” that we may pick by utilizing its class.</p> <p>Finally, let’s write a function that will loop over all of the jobs and store them to a csv file.</p> <p>Take note that we are getting the maximum amount of pages so that the crawler will stop when we reach the last page.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def getJobsForQuery(query):  
    data=[]  
    maxPages=999  
    for number in range(maxPages):  
        maxPages,urls=getPageUrls(query,number+1)  
        for url in urls:  
            try:  
                page=processPage(url)  
                data.append(page)  
            except:  
                pass  
        print("finished Page number: "+str(number+1))  
    #Save the data to a csv file  
    pd.DataFrame(data).to_csv("jobs_"+query+".csv")
</code></pre></div></div> <p>Now let’s scrape some data scientist offers:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>driver = webdriver.Chrome(ChromeDriverManager().install(),options=chrome_options)  
getJobsForQuery("data scientist")
</code></pre></div></div> <p>What we got:</p> <p><a href="https://postimg.cc/WD5YkYSh" rel="external nofollow noopener" target="_blank"><img src="https://i.postimg.cc/hjBkNHdb/image.png" alt="image.png"></a> A Sample of scraped jobs</p> <h1 id="conclusion">Conclusion</h1> <p>In this post, we learnt about web scraping, why it’s crucial for every aspiring data scientist, and the many techniques of extracting jobs from Indeed.</p> <p>if you made it this far Congratulations. Thank you for reading, and I hope you found the material interesting. Feel free to contact me on social media for personal contact or conversation.</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2021/correct-mindset/">The correct mindset</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2020/ECC-innovation-hackathon/">ECC innovation hackathon</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2022/Morocco,-a-booming-electric-cars-market-and-soon-an-autonomous-vehiculs-hotspot!/">Morocco, a booming electric cars market and soon an autonomous vehicules hotspot!</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2020/Corona-aid/">Humanitarian aid amidst the COVID-19 pandemic</a> </li> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2023 Yassir Birouk. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?07b8786bab9b4abe90d10e61f7d12ff7" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>